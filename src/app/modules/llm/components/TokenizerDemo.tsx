'use client'

import { useState, useEffect } from 'react'

interface TokenizerDemoProps {
  initialText?: string
}

export default function TokenizerDemo({ initialText = 'ì•ˆë…•í•˜ì„¸ìš”! LLMì„ ë°°ìš°ê³  ìˆìŠµë‹ˆë‹¤.' }: TokenizerDemoProps) {
  const [text, setText] = useState(initialText)
  const [tokenizer, setTokenizer] = useState('gpt')
  const [tokens, setTokens] = useState<string[]>([])
  const [tokenCount, setTokenCount] = useState(0)

  // ê°„ë‹¨í•œ í† í¬ë‚˜ì´ì € ì‹œë®¬ë ˆì´ì…˜ (ì‹¤ì œë¡œëŠ” ê° ëª¨ë¸ì˜ ì‹¤ì œ í† í¬ë‚˜ì´ì €ë¥¼ ì‚¬ìš©í•´ì•¼ í•¨)
  const tokenizeText = (text: string, tokenizerType: string) => {
    let tokenized: string[] = []
    
    switch (tokenizerType) {
      case 'gpt':
        // GPT ìŠ¤íƒ€ì¼: BPE (Byte Pair Encoding) ì‹œë®¬ë ˆì´ì…˜
        // í•œê¸€ì€ ë³´í†µ ê¸€ì ë‹¨ìœ„ë¡œ, ì˜ì–´ëŠ” ì„œë¸Œì›Œë“œ ë‹¨ìœ„ë¡œ
        tokenized = text.match(/[\u3131-\uD79D]|[a-zA-Z]+|[0-9]+|[^\s\wê°€-í£]/g) || []
        break
      
      case 'claude':
        // Claude ìŠ¤íƒ€ì¼: ì¡°ê¸ˆ ë” ì„¸ë°€í•œ ë¶„í• 
        tokenized = text.match(/[\u3131-\uD79D]|[a-zA-Z]+\'?[a-zA-Z]*|[0-9]+|[^\s\wê°€-í£]/g) || []
        break
      
      case 'bert':
        // BERT ìŠ¤íƒ€ì¼: WordPiece ì‹œë®¬ë ˆì´ì…˜
        tokenized = text.split(/\s+/).flatMap(word => {
          if (/^[ê°€-í£]+$/.test(word)) {
            // í•œê¸€ì€ ìŒì ˆ ë‹¨ìœ„ë¡œ
            return word.split('')
          } else if (/^[a-zA-Z]+$/.test(word)) {
            // ì˜ì–´ëŠ” ì„œë¸Œì›Œë“œë¡œ (ê°„ë‹¨íˆ ì‹œë®¬ë ˆì´ì…˜)
            if (word.length > 5) {
              return [word.slice(0, 3) + '##', '##' + word.slice(3)]
            }
            return [word]
          }
          return [word]
        }).filter(Boolean)
        break
      
      default:
        tokenized = text.split(/\s+/)
    }
    
    return tokenized
  }

  useEffect(() => {
    const newTokens = tokenizeText(text, tokenizer)
    setTokens(newTokens)
    setTokenCount(newTokens.length)
  }, [text, tokenizer])

  return (
    <div className="demo-container">
      <div className="demo-controls">
        <select 
          className="tokenizer-select" 
          value={tokenizer}
          onChange={(e) => setTokenizer(e.target.value)}
        >
          <option value="gpt">GPT-3/4 Tokenizer</option>
          <option value="claude">Claude Tokenizer</option>
          <option value="bert">BERT Tokenizer</option>
        </select>
        <textarea 
          className="demo-input" 
          placeholder="ì—¬ê¸°ì— í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”..."
          value={text}
          onChange={(e) => setText(e.target.value)}
        />
      </div>
      <div className="demo-output">
        <div className="token-count">í† í° ìˆ˜: <span className="font-bold">{tokenCount}</span></div>
        <div className="tokenized-result">
          {tokens.map((token, index) => (
            <span key={index} className="token">
              {token}
            </span>
          ))}
        </div>
      </div>
      
      <div className="mt-4 p-4 bg-blue-50 dark:bg-blue-900/20 rounded-lg">
        <h4 className="font-semibold text-blue-800 dark:text-blue-200 mb-2">ğŸ’¡ í† í¬ë‚˜ì´ì €ë³„ íŠ¹ì§•</h4>
        <ul className="space-y-2 text-sm text-blue-700 dark:text-blue-300">
          <li><strong>GPT:</strong> BPE(Byte Pair Encoding) ë°©ì‹, í•œê¸€ì€ ì£¼ë¡œ ê¸€ì ë‹¨ìœ„ë¡œ ë¶„í• </li>
          <li><strong>Claude:</strong> ê°œì„ ëœ BPE, ë¬¸ë§¥ì„ ê³ ë ¤í•œ ë” íš¨ìœ¨ì ì¸ í† í°í™”</li>
          <li><strong>BERT:</strong> WordPiece ë°©ì‹, ì„œë¸Œì›Œë“œ ë‹¨ìœ„ë¡œ ë¶„í•  (## í”„ë¦¬í”½ìŠ¤ ì‚¬ìš©)</li>
        </ul>
      </div>
    </div>
  )
}